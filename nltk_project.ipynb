{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nltk project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "mount_file_id": "1c0O-LVRHpxmRTUs87wBdxq83t2AUX5pE",
      "authorship_tag": "ABX9TyP9S+h+DF1MI+bCIGgfOUV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saivarun08777/saivarun08777/blob/main/nltk_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUKouiokh003"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from transformers import BertTokenizer, TFBertModel, TFAutoModel,AutoTokenizer"
      ],
      "metadata": {
        "id": "9lUYxcogs7fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print('Number of replicas:', strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "id": "AA2mrQ5ck_Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "hqZP8qV5i8tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/nltk/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/nltk/test.csv')"
      ],
      "metadata": {
        "id": "Gf8YnpkYjI1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape, test_data.shape"
      ],
      "metadata": {
        "id": "x4MQCZNCjq3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info(), test_data.info()"
      ],
      "metadata": {
        "id": "-wIK6im0jufV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe"
      ],
      "metadata": {
        "id": "GukzjouXkBAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.describe"
      ],
      "metadata": {
        "id": "npAWW7qmkOf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.isnull().sum()"
      ],
      "metadata": {
        "id": "HPST0DFxkUI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.isnull().sum()"
      ],
      "metadata": {
        "id": "xL3XpAUBkh2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "hbLWIMUekmYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "MiYRpcyykxJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns"
      ],
      "metadata": {
        "id": "eZb21OLNnj5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.columns"
      ],
      "metadata": {
        "id": "2aWRLDHWnouC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dtypes"
      ],
      "metadata": {
        "id": "BESBZnIxoizT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.dtypes"
      ],
      "metadata": {
        "id": "FqaThk8Mq4So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['lang_abv'].unique()"
      ],
      "metadata": {
        "id": "6SY5EoxCrXf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['language'].unique()"
      ],
      "metadata": {
        "id": "u4y1GB_csvd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['label'].unique().sum()"
      ],
      "metadata": {
        "id": "GLcb7XUwtDS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['label'].unique()"
      ],
      "metadata": {
        "id": "Q72TLjqgtFC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['lang_abv'].unique()"
      ],
      "metadata": {
        "id": "5ziC1SKGuOjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['language'].unique()"
      ],
      "metadata": {
        "id": "S4J7a47RuWkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_data.drop('lang_abv',axis=1)\n",
        "test_data=test_data.drop('lang_abv',axis=1)"
      ],
      "metadata": {
        "id": "0u8ThNdh2xpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "hFyypCFb2_uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "fEuDzSN43EY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "HGygqG7q3Hgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "metadata": {
        "id": "n7tL8ZCi3NHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(train_data['language'], palette='bright')\n",
        "sns.set(rc={'figure.figsize':(15,15)})"
      ],
      "metadata": {
        "id": "SdAHqcwptehn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(train_data['label'], palette='deep')"
      ],
      "metadata": {
        "id": "5qhUkWxy2ZVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(test_data['language'], palette='bright')\n",
        "sns.set(rc={'figure.figsize':(5,5)})"
      ],
      "metadata": {
        "id": "-S_vQXd_vCIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, frequencies = np.unique(train_data.language.values, return_counts = True)\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.pie(frequencies,labels = labels, autopct = '%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y90CNcXA0Gdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, frequencies = np.unique(test_data.language.values, return_counts = True)\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.pie(frequencies,labels = labels, autopct = '%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fFLzyyrI0-e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "id": "_WRlx-qGuIjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tokenizer"
      ],
      "metadata": {
        "id": "VComTLUyuVKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install backend tokenizer"
      ],
      "metadata": {
        "id": "FXIosi3Mu20v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install slow tokenizer"
      ],
      "metadata": {
        "id": "t5xeLYXzvEsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fast tokenizer"
      ],
      "metadata": {
        "id": "7SB2YqoLvJMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install serialization"
      ],
      "metadata": {
        "id": "RFd69xM0vSO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tokenizers"
      ],
      "metadata": {
        "id": "jPOVm74ivbgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenizer"
      ],
      "metadata": {
        "id": "ZRIaIAzAvohY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "ENexzAJZ6MsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.vocab)"
      ],
      "metadata": {
        "id": "eR01CbJs_K8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(s):\n",
        "    tokens = list(tokenizer.tokenize(s))\n",
        "    tokens.append('[SEP]')\n",
        "    return tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "metadata": {
        "id": "IEb6MhMZ_Z3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_encode( premises,hypotheses,tokenizer):\n",
        "    \n",
        "    num_examples = len(hypotheses)\n",
        "\n",
        "    sentence1 = tf.ragged.constant([\n",
        "        encode_sentence(s)\n",
        "        for s in np.array(hypotheses)])\n",
        "    sentence2 = tf.ragged.constant([\n",
        "        encode_sentence(s)\n",
        "        for s in np.array(premises)])\n",
        "\n",
        "    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
        "    input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
        "\n",
        "    input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
        "\n",
        "    type_cls = tf.zeros_like(cls)\n",
        "    type_s1 = tf.zeros_like(sentence1)\n",
        "    type_s2 = tf.ones_like(sentence2)\n",
        "    input_type_ids = tf.concat(\n",
        "        [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
        "\n",
        "    inputs = {\n",
        "        'input_word_ids': input_word_ids.to_tensor(),\n",
        "        'input_mask': input_mask,\n",
        "        'input_type_ids': input_type_ids}\n",
        "\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "xDqx-9Fn_lFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    bert_encoder = TFBertModel.from_pretrained(model_name)\n",
        "    input_word_ids = tf.keras.Input(shape = (None,),dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape = (None,),dtype=tf.int32, name=\"input_mask\")\n",
        "    input_type_ids = tf.keras.Input(shape = (None,),dtype=tf.int32, name=\"input_type_ids\")\n",
        "    \n",
        "    embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]\n",
        "    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "2ht030KhACaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = bert_encode(train_data.premise.values, train_data.hypothesis.values, tokenizer)"
      ],
      "metadata": {
        "id": "C1dRIN5SCV86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    bert_encoder = TFBertModel.from_pretrained(model_name)\n",
        "    input_word_ids = tf.keras.Input(shape = (None,),dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape = (None,),dtype=tf.int32, name=\"input_mask\")\n",
        "    input_type_ids = tf.keras.Input(shape = (None,),dtype=tf.int32, name=\"input_type_ids\")\n",
        "    \n",
        "    embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]\n",
        "    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "W67dkiNM1VBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = build_model()\n",
        "    model.summary()"
      ],
      "metadata": {
        "id": "0u2kOPFh1dbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_input, train_data.label.values, epochs = 5, verbose = 1, batch_size = 16, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "gYAyue6D14WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = bert_encode(test_data.premise.values, test_data.hypothesis.values, tokenizer)"
      ],
      "metadata": {
        "id": "o6EJKj023kgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "v6eKzWms3141"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [np.argmax(i) for i in model.predict(test_input)]"
      ],
      "metadata": {
        "id": "RjktjqkJ4EdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_data = test_data.id.copy().to_frame()\n",
        "pred_data['prediction'] = predictions"
      ],
      "metadata": {
        "id": "ch6zCxOd4bp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_data.head(10)"
      ],
      "metadata": {
        "id": "QUXUo59S4v3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_data.to_csv(\"pred_data.csv\", index = False)"
      ],
      "metadata": {
        "id": "k9kbS85H4--Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(pred_data['prediction'], palette='bright')"
      ],
      "metadata": {
        "id": "T-juzOXo5ml_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}